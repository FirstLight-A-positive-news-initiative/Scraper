{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "365ef7cd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "365ef7cd",
        "outputId": "33534f46-38eb-409e-b948-400578d91429"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from datetime import datetime\n",
        "import pandas as pd\n",
        "\n",
        "#BERT\n",
        "#Positivity Score\n",
        "from transformers import pipeline\n",
        "# Allocate a pipeline for sentiment-analysis\n",
        "classifier = pipeline('sentiment-analysis')\n",
        "\n",
        "#Summary\n",
        "import torch\n",
        "from transformers import T5Tokenizer, T5ForConditionalGeneration, T5Config\n",
        "model = T5ForConditionalGeneration.from_pretrained('t5-small')\n",
        "tokenizer = T5Tokenizer.from_pretrained('t5-small')\n",
        "device = torch.device('cpu')\n",
        "\n",
        "#Capitalize the Sentences\n",
        "import textwrap\n",
        "import nltk.data\n",
        "sent_tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
        "import re\n",
        "\n",
        "import pymongo\n",
        "from pymongo import MongoClient\n",
        "import ssl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7e629699",
      "metadata": {
        "id": "7e629699"
      },
      "outputs": [],
      "source": [
        "datedata=pd.read_csv(\"./LastRunDate.csv\")\n",
        "pastdate=datetime.fromtimestamp(datedata.loc[datedata[\"Scraper and Model\"]==\"sports\", \"Date\"])\n",
        "lastdate=pastdate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d421440e",
      "metadata": {
        "id": "d421440e"
      },
      "outputs": [],
      "source": [
        "def convert_date(date_string):\n",
        "    # February 7, 2022 10:07 AM\n",
        "    \n",
        "    datetime_object = datetime.strptime(date_string, \"%B %d, %Y %H:%M %p\")\n",
        "    return (datetime_object)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "878cd6e6",
      "metadata": {
        "id": "878cd6e6"
      },
      "outputs": [],
      "source": [
        "def collect_links(page, last_run_date):\n",
        "    stop = False\n",
        "    req = requests.get(\"https://www.india.com/sports/page/{}\".format(page))\n",
        "    if(req.status_code == 200):\n",
        "        soup = BeautifulSoup(req.text, \"html.parser\")\n",
        "        try:\n",
        "            section = soup.find(class_ = \"listing-cities-news\")\n",
        "            news_items = section.findAll(class_ = \"catPgListitem\")\n",
        "            news_links = []\n",
        "            for item in news_items:\n",
        "                try:\n",
        "                    formatted_date = convert_date(item.find(class_ = \"byline\").text.split(\"\\n\")[2].strip()[:-4])\n",
        "                    if(formatted_date < last_run_date):\n",
        "                        stop = True\n",
        "                        break\n",
        "                    news_links.append(item.find(\"a\").attrs[\"href\"])\n",
        "                except:\n",
        "                    continue\n",
        "            return news_links, stop\n",
        "        except:\n",
        "            print(\"Page Error.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8ba5e543",
      "metadata": {
        "id": "8ba5e543"
      },
      "outputs": [],
      "source": [
        "def update_last_run_date(date):\n",
        "    datedata=pd.read_csv(\"./LastRunDate.csv\")\n",
        "    datedata.loc[datedata[\"Scraper and Model\"]==\"sports\", \"Date\"]=datetime.timestamp(date)\n",
        "    datedata.to_csv(\"LastRunDate.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "57fbb494",
      "metadata": {},
      "outputs": [],
      "source": [
        "news_gathered=[]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "95e3110e",
      "metadata": {
        "id": "95e3110e"
      },
      "outputs": [],
      "source": [
        "newdate=lastdate\n",
        "def gather_news(news_links):\n",
        "    global newdate\n",
        "    for news_link in news_links:\n",
        "        req = requests.get(news_link)\n",
        "        soup = BeautifulSoup(req.text, \"html.parser\")\n",
        "        try:\n",
        "            article = soup.find(class_ = \"article-page\")\n",
        "            heading = article.find(\"h1\").text\n",
        "            date = convert_date(article.find(class_ = \"authors-m\").find(\"aside\").text.split(\": \")[1].strip()[:-4])\n",
        "            if newdate<date:\n",
        "                newdate=date\n",
        "            image_wrapper = article.find(class_ = \"content-wrap\").figure.div.img\n",
        "            image_link = image_wrapper.attrs[\"data-lazy-src\"]\n",
        "            content_body = article.find(class_ = \"articleBody\")\n",
        "            paragraphs = content_body.findAll(\"p\")\n",
        "            content = \"\"\n",
        "            for para in paragraphs:\n",
        "                content += para.text.split(\"Also Read\")[0]\n",
        "\n",
        "            news_gathered.append(\n",
        "                {\n",
        "                    \"title\": heading,\n",
        "                    \"link\": news_link,\n",
        "                    \"image_link\": image_link,\n",
        "                    \"summary\": content,\n",
        "                    \"positivity_score\": 0,\n",
        "                    \"date\": date,\n",
        "                    \"genre\": \"sports\"\n",
        "                }\n",
        "            )\n",
        "        except:\n",
        "            continue\n",
        "    return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c9f6de57",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c9f6de57",
        "outputId": "59bf70f1-359e-4d8b-d6bf-ff773c6cf416"
      },
      "outputs": [],
      "source": [
        "page = 1\n",
        "while(True):\n",
        "    output = collect_links(page, lastdate)\n",
        "    stop = output[1]\n",
        "    news_links = output[0]\n",
        "    \n",
        "    gather_news(news_links)\n",
        "    print(stop)\n",
        "    if(stop):\n",
        "        break\n",
        "    else:\n",
        "        page += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7c691f39",
      "metadata": {},
      "outputs": [],
      "source": [
        "len(news_gathered)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "UnyC5pvt8ZN6",
      "metadata": {
        "id": "UnyC5pvt8ZN6"
      },
      "outputs": [],
      "source": [
        "update_last_run_date(newdate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8ed1a377",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 389
        },
        "id": "8ed1a377",
        "outputId": "a92f3191-e02e-449b-9892-467fac0f1ccf"
      },
      "outputs": [],
      "source": [
        "for i in range(len(news_gathered)):\n",
        "    x={'label': 'NEGATIVE', 'score': 1}\n",
        "    try:\n",
        "        x = classifier(news_gathered[i][\"summary\"][:1500])[0]\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    news_gathered[i][\"positivity_score\"] = x['score']/2+0.5 if x['label']=='POSITIVE' else (0.5-x['score']/2)\n",
        "    news_gathered[i][\"positivity_score\"] = int(float(news_gathered[i][\"positivity_score\"])*100)\n",
        "    if news_gathered[i][\"genre\"]==\"science\" or news_gathered[i][\"genre\"]==\"offbeat\":\n",
        "        news_gathered[i][\"positivity_score\"] += 50\n",
        "        news_gathered[i][\"positivity_score\"] = min(news_gathered[i][\"positivity_score\"], 100)\n",
        "pd.DataFrame(news_gathered).head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "VYxe2PiG2o8d",
      "metadata": {
        "id": "VYxe2PiG2o8d"
      },
      "outputs": [],
      "source": [
        "#Removes non-alphabetic characters:\n",
        "def text_strip(column):\n",
        "    for row in column:\n",
        "        \n",
        "        #ORDER OF REGEX IS VERY VERY IMPORTANT!!!!!!\n",
        "        \n",
        "        row=re.sub(\"(\\\\t)\", ' ', str(row)).lower() #remove escape charecters\n",
        "        row=re.sub(\"(\\\\r)\", ' ', str(row)).lower() \n",
        "        row=re.sub(\"(\\\\n)\", ' ', str(row)).lower()\n",
        "        \n",
        "        row=re.sub(\"(__+)\", ' ', str(row)).lower()   #remove _ if it occors more than one time consecutively\n",
        "        row=re.sub(\"(--+)\", ' ', str(row)).lower()   #remove - if it occors more than one time consecutively\n",
        "        row=re.sub(\"(~~+)\", ' ', str(row)).lower()   #remove ~ if it occors more than one time consecutively\n",
        "        row=re.sub(\"(\\+\\++)\", ' ', str(row)).lower()   #remove + if it occors more than one time consecutively\n",
        "        row=re.sub(\"(\\.\\.+)\", ' ', str(row)).lower()   #remove . if it occors more than one time consecutively\n",
        "        \n",
        "        row=re.sub(r\"[<>()|&©ø\\[\\]\\'\\\",;?~*!]\", ' ', str(row)).lower() #remove <>()|&©ø\"',;?~*!\n",
        "        \n",
        "        row=re.sub(\"(mailto:)\", ' ', str(row)).lower() #remove mailto:\n",
        "        row=re.sub(r\"(\\\\x9\\d)\", ' ', str(row)).lower() #remove \\x9* in text\n",
        "        row=re.sub(\"([iI][nN][cC]\\d+)\", 'INC_NUM', str(row)).lower() #replace INC nums to INC_NUM\n",
        "        row=re.sub(\"([cC][mM]\\d+)|([cC][hH][gG]\\d+)\", 'CM_NUM', str(row)).lower() #replace CM# and CHG# to CM_NUM\n",
        "        \n",
        "        \n",
        "        row=re.sub(\"(\\.\\s+)\", ' ', str(row)).lower() #remove full stop at end of words(not between)\n",
        "        row=re.sub(\"(\\-\\s+)\", ' ', str(row)).lower() #remove - at end of words(not between)\n",
        "        row=re.sub(\"(\\:\\s+)\", ' ', str(row)).lower() #remove : at end of words(not between)\n",
        "        \n",
        "        row=re.sub(\"(\\s+.\\s+)\", ' ', str(row)).lower() #remove any single charecters hanging between 2 spaces\n",
        "        \n",
        "        #Replace any url as such https://abc.xyz.net/browse/sdf-5327 ====> abc.xyz.net\n",
        "        try:\n",
        "            url = re.search(r'((https*:\\/*)([^\\/\\s]+))(.[^\\s]+)', str(row))\n",
        "            repl_url = url.group(3)\n",
        "            row = re.sub(r'((https*:\\/*)([^\\/\\s]+))(.[^\\s]+)',repl_url, str(row))\n",
        "        except:\n",
        "            pass #there might be emails with no url in them\n",
        "        \n",
        "\n",
        "        \n",
        "        row = re.sub(\"(\\s+)\",' ',str(row)).lower() #remove multiple spaces\n",
        "        \n",
        "        #Should always be last\n",
        "        row=re.sub(\"(\\s+.\\s+)\", ' ', str(row)).lower() #remove any single charecters hanging between 2 spaces\n",
        "\n",
        "        row.strip().replace(\"\\n\",\"\")\n",
        "        \n",
        "        yield row"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "22AJKdG03h6G",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "22AJKdG03h6G",
        "outputId": "03e8f834-da9b-4c73-96f7-b7425c43962c"
      },
      "outputs": [],
      "source": [
        "for i in range(len(news_gathered)):\n",
        "    content=news_gathered[i][\"summary\"]\n",
        "\n",
        "    preprocess_text = content.strip().replace(\"\\n\",\"\")\n",
        "    t5_prepared_Text = \"summarize: \"+preprocess_text\n",
        "\n",
        "    tokenized_text = tokenizer.encode(t5_prepared_Text, return_tensors=\"pt\").to(device)\n",
        "\n",
        "\n",
        "    # summmarize \n",
        "    summary_ids = model.generate(tokenized_text,\n",
        "                                        num_beams=4,\n",
        "                                        no_repeat_ngram_size=2,\n",
        "                                        min_length=50,\n",
        "                                        max_length=200,\n",
        "                                        early_stopping=True)\n",
        "\n",
        "    output = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "    sentences = sent_tokenizer.tokenize(output)\n",
        "    sentences = [sent.capitalize() for sent in sentences]\n",
        "    output=\"\"\n",
        "    for sent in sentences:\n",
        "        output+=sent+' '\n",
        "    news_gathered[i][\"summary\"]=output.strip()\n",
        "    print(\"Summarised:\", i+1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "uj__E5Xj3lFB",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 866
        },
        "id": "uj__E5Xj3lFB",
        "outputId": "5f82c129-6108-46cc-8e65-47e958e223ad"
      },
      "outputs": [],
      "source": [
        "pd.DataFrame(news_gathered)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "LQsItVIe3mct",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 959
        },
        "id": "LQsItVIe3mct",
        "outputId": "a42081f5-0e0f-4947-85ef-044a4d97a9b3"
      },
      "outputs": [],
      "source": [
        "news_gathered = [{k: v for k, v in d.items() if k != 'desc'} for d in news_gathered]\n",
        "pd.DataFrame(news_gathered).head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0376424a",
      "metadata": {},
      "outputs": [],
      "source": [
        "username=\"\"\n",
        "password=\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aQZgjS-C3nnw",
      "metadata": {
        "id": "aQZgjS-C3nnw"
      },
      "outputs": [],
      "source": [
        "def get_database():\n",
        "    # Provide the mongodb atlas url to connect python to mongodb using pymongo\n",
        "    CONNECTION_STRING = f\"mongodb+srv://{username}:{password}@cluster0.oani9.mongodb.net/firstlight?retryWrites=true&w=majority\"\n",
        "    try:\n",
        "        conn = MongoClient(CONNECTION_STRING, ssl_cert_reqs=ssl.CERT_NONE)\n",
        "        print(\"Connected successfully!!!\")\n",
        "        return conn.firstlight\n",
        "    except:  \n",
        "        print(\"Could not connect to MongoDB\")\n",
        "        return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Wb49YvDs3pMq",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wb49YvDs3pMq",
        "outputId": "17cfdfb4-c175-42c5-d4e1-ec11b52aebc8"
      },
      "outputs": [],
      "source": [
        "db = get_database()\n",
        "try:\n",
        "    db[\"news\"].insert_many(news_gathered)\n",
        "    print(\"Success\")\n",
        "except Exception as e:\n",
        "    print(e)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Scraper_Sports.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
