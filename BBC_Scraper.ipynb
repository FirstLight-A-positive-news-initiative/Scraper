{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbae7de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "#BERT\n",
    "from transformers import pipeline\n",
    "# Allocate a pipeline for sentiment-analysis\n",
    "classifier = pipeline('sentiment-analysis')\n",
    "import ssl\n",
    "\n",
    "#Summary\n",
    "import torch\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration, T5Config\n",
    "model = T5ForConditionalGeneration.from_pretrained('t5-small')\n",
    "tokenizer = T5Tokenizer.from_pretrained('t5-small')\n",
    "device = torch.device('cpu')\n",
    "\n",
    "#Capitalize the Sentences\n",
    "import textwrap\n",
    "import nltk.data\n",
    "sent_tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "\n",
    "import pymongo\n",
    "from pymongo import MongoClient\n",
    "\n",
    "from bs4 import BeautifulSoup \n",
    "import re\n",
    "import urllib.request, urllib.parse, urllib.error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9de5075",
   "metadata": {},
   "outputs": [],
   "source": [
    "bbc_url = 'https://www.bbc.com'\n",
    "bbc_url_news = 'https://www.bbc.com/news'\n",
    "world_url = 'https://edition.cnn.com/world'\n",
    "politics_url = 'https://edition.cnn.com/politics'\n",
    "health_url = 'https://edition.cnn.com/health'\n",
    "entertainment_url = 'https://edition.cnn.com/entertainment'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea751a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "datedata=pd.read_csv(\"./LastRunDate.csv\")\n",
    "pastdate=datetime.fromtimestamp(datedata.loc[datedata[\"Scraper and Model\"]==\"bbc\", \"Date\"])\n",
    "lastdate=pastdate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de5cfa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getParseUrl(link, genre):\n",
    "    driver = getDriver()\n",
    "    if genre == 'sports':\n",
    "        driver.get(link + '/sport')\n",
    "    else:\n",
    "        driver.get(link + '/news')\n",
    "        button = driver.find_element_by_link_text(genre)\n",
    "        button.click()\n",
    "    webContent = driver.page_source\n",
    "    data = BeautifulSoup(webContent, 'html.parser')\n",
    "    driver.close()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1539db35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getParseUrlStatic(link):\n",
    "    response = urllib.request.urlopen(link)\n",
    "    webContent = response.read()\n",
    "    \n",
    "    data = BeautifulSoup(webContent, 'html.parser')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cfeb758",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNewsLinks(data):\n",
    "    headlines = data.find_all(class_ = \"gs-c-promo-heading\")\n",
    "    links = []\n",
    "    for headline in headlines:\n",
    "        try:\n",
    "            link = headline[\"href\"]\n",
    "            if link[:5] != 'https':\n",
    "                link = bbc_url + link\n",
    "            links.append(link)\n",
    "        except:\n",
    "            # print(\"Cannot find the link\")\n",
    "            pass\n",
    "    return links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f8c98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDriver():\n",
    "    driver = webdriver.Chrome(executable_path=r'./chromedriver_win32/chromedriver')\n",
    "    return driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a46a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getStringFromTags(tag):\n",
    "    data = tag.contents\n",
    "    string = \"\"\n",
    "    for content in data:\n",
    "        try:\n",
    "            string += content\n",
    "        except:\n",
    "            string += getStringFromTags(content)\n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8258a4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAppropriateGenre(genre):\n",
    "    if genre == 'Tech':\n",
    "        genre = 'technology'\n",
    "    elif genre == 'Climate':\n",
    "        genre = 'climate'\n",
    "    elif genre == 'Science':\n",
    "        genre = 'science'\n",
    "    elif genre == 'World' or genre == 'Asia':\n",
    "        genre = 'world'\n",
    "    elif genre == 'Business':\n",
    "        genre = 'business'\n",
    "    elif genre == 'sports':\n",
    "        genre='sports'\n",
    "    else:\n",
    "        genre = 'entertainment'\n",
    "    return genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dee28b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanTitle(title):\n",
    "    if title[:6] == 'COP26:':\n",
    "        title = title.split('COP26: ', 1)[1]\n",
    "    return title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092bf9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNewsFromLink(link, genre):\n",
    "    news = {}\n",
    "    try:\n",
    "        data = getParseUrlStatic(link)\n",
    "        news = {}\n",
    "        news['title'] = cleanTitle(data.find('h1', {'id': 'main-heading'}).contents[0])\n",
    "        news['summary'] = \"\"\n",
    "        divs = data.findAll('div', {'data-component': 'text-block'})\n",
    "        for div in divs:\n",
    "            news['summary'] += getStringFromTags(div)\n",
    "        if int(data.find('img')['width'])>100:\n",
    "            news['image_link'] = data.find('img')['src']\n",
    "        else:\n",
    "            news['image_link'] =\"\"\n",
    "        i=0\n",
    "        while i<len(data.find_all('img')) and int(data.find_all('img')[i]['width'])<100:\n",
    "            i+=1\n",
    "        if i<len(data.find_all('img')):\n",
    "            news['image_link'] = data.find_all('img')[i]['src']\n",
    "        news['link'] = link\n",
    "        news['positivity_score'] = 80\n",
    "        utcdiff=datetime.now()-datetime.utcnow()\n",
    "        news['date'] = datetime.strptime(data.find('time')['datetime'][:-5], '%Y-%m-%dT%H:%M:%S') + utcdiff\n",
    "        news['genre'] = getAppropriateGenre(genre)\n",
    "        if news['summary'] == '':\n",
    "            news = {}\n",
    "        if pastdate>=news['date']:\n",
    "            news = {}\n",
    "        global lastdate\n",
    "        if lastdate<news['date']:\n",
    "            lastdate=news['date']\n",
    "    except:\n",
    "        # print(\"Cannot get this news \" + link)\n",
    "        news={}\n",
    "    return news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a4aea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDataFromUrl(url, genre):\n",
    "    data = getParseUrl(url, genre)\n",
    "    links = getNewsLinks(data)\n",
    "    news = [getNewsFromLink(link, genre) for link in links]\n",
    "    return list(filter(None, news))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a976288",
   "metadata": {},
   "outputs": [],
   "source": [
    "news = []\n",
    "for genre in ['Climate', 'World', 'Tech', 'Business', 'Science', 'Entertainment & Arts']:\n",
    "    cur_news = getDataFromUrl(bbc_url, genre)\n",
    "    for new in cur_news:\n",
    "        news.append(new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac90e703",
   "metadata": {},
   "outputs": [],
   "source": [
    "datedata=pd.read_csv(\"./LastRunDate.csv\")\n",
    "datedata.loc[datedata[\"Scraper and Model\"]==\"bbc\", \"Date\"]=datetime.timestamp(lastdate)\n",
    "datedata.to_csv(\"LastRunDate.csv\", index=False)\n",
    "print(\"Latest News Found:\", lastdate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63489f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc226d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(news)):\n",
    "    x={'label': 'NEGATIVE', 'score': 1}\n",
    "    try:\n",
    "        x = classifier(news[i][\"summary\"])[0]\n",
    "    except:\n",
    "        pass\n",
    "    z=classifier(' '.join(news[i][\"summary\"].split()[:300]))[0]\n",
    "    news[i][\"positivity_score\"] = max(x['score']/2+0.5 if x['label']=='POSITIVE' else (0.5-x['score']/2), z['score']/2+0.5 if z['label']=='POSITIVE' else (0.5-z['score']/2))\n",
    "    news[i][\"positivity_score\"] = int(float(news[i][\"positivity_score\"])*100)\n",
    "    if news[i][\"genre\"]==\"science\":\n",
    "        news[i][\"positivity_score\"] += 50\n",
    "        news[i][\"positivity_score\"] = min(news[i][\"positivity_score\"], 100)\n",
    "    if news[i][\"genre\"]==\"technology\" or news[i][\"genre\"]==\"business\" or news[i][\"genre\"]==\"entertainment\":\n",
    "        news[i][\"positivity_score\"] += 25\n",
    "        news[i][\"positivity_score\"] = min(news[i][\"positivity_score\"], 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92aa6f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d351cf09",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(news)):\n",
    "    if news[i][\"genre\"] == 'climate':\n",
    "        news[i][\"genre\"] = 'science'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75800c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "news = pd.DataFrame(news).dropna()\n",
    "news.drop_duplicates(keep='first', inplace=True)\n",
    "news.drop_duplicates(['title', 'genre'], keep='first', inplace=True)\n",
    "news = news.to_dict('records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87dd76ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removes non-alphabetic characters:\n",
    "def text_strip(column):\n",
    "    for row in column:\n",
    "        \n",
    "        #ORDER OF REGEX IS VERY VERY IMPORTANT!!!!!!\n",
    "        \n",
    "        row=re.sub(\"(\\\\t)\", ' ', str(row)).lower() #remove escape charecters\n",
    "        row=re.sub(\"(\\\\r)\", ' ', str(row)).lower() \n",
    "        row=re.sub(\"(\\\\n)\", ' ', str(row)).lower()\n",
    "        \n",
    "        row=re.sub(\"(__+)\", ' ', str(row)).lower()   #remove _ if it occors more than one time consecutively\n",
    "        row=re.sub(\"(--+)\", ' ', str(row)).lower()   #remove - if it occors more than one time consecutively\n",
    "        row=re.sub(\"(~~+)\", ' ', str(row)).lower()   #remove ~ if it occors more than one time consecutively\n",
    "        row=re.sub(\"(\\+\\++)\", ' ', str(row)).lower()   #remove + if it occors more than one time consecutively\n",
    "        row=re.sub(\"(\\.\\.+)\", ' ', str(row)).lower()   #remove . if it occors more than one time consecutively\n",
    "        \n",
    "        row=re.sub(r\"[<>()|&©ø\\[\\]\\'\\\",;?~*!]\", ' ', str(row)).lower() #remove <>()|&©ø\"',;?~*!\n",
    "        \n",
    "        row=re.sub(\"(mailto:)\", ' ', str(row)).lower() #remove mailto:\n",
    "        row=re.sub(r\"(\\\\x9\\d)\", ' ', str(row)).lower() #remove \\x9* in text\n",
    "        row=re.sub(\"([iI][nN][cC]\\d+)\", 'INC_NUM', str(row)).lower() #replace INC nums to INC_NUM\n",
    "        row=re.sub(\"([cC][mM]\\d+)|([cC][hH][gG]\\d+)\", 'CM_NUM', str(row)).lower() #replace CM# and CHG# to CM_NUM\n",
    "        \n",
    "        \n",
    "        row=re.sub(\"(\\.\\s+)\", ' ', str(row)).lower() #remove full stop at end of words(not between)\n",
    "        row=re.sub(\"(\\-\\s+)\", ' ', str(row)).lower() #remove - at end of words(not between)\n",
    "        row=re.sub(\"(\\:\\s+)\", ' ', str(row)).lower() #remove : at end of words(not between)\n",
    "        \n",
    "        row=re.sub(\"(\\s+.\\s+)\", ' ', str(row)).lower() #remove any single charecters hanging between 2 spaces\n",
    "        \n",
    "        #Replace any url as such https://abc.xyz.net/browse/sdf-5327 ====> abc.xyz.net\n",
    "        try:\n",
    "            url = re.search(r'((https*:\\/*)([^\\/\\s]+))(.[^\\s]+)', str(row))\n",
    "            repl_url = url.group(3)\n",
    "            row = re.sub(r'((https*:\\/*)([^\\/\\s]+))(.[^\\s]+)',repl_url, str(row))\n",
    "        except:\n",
    "            pass #there might be emails with no url in them\n",
    "        \n",
    "\n",
    "        \n",
    "        row = re.sub(\"(\\s+)\",' ',str(row)).lower() #remove multiple spaces\n",
    "        \n",
    "        #Should always be last\n",
    "        row=re.sub(\"(\\s+.\\s+)\", ' ', str(row)).lower() #remove any single charecters hanging between 2 spaces\n",
    "\n",
    "        row.strip().replace(\"\\n\",\"\")\n",
    "        \n",
    "        yield row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7bb49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(news)):\n",
    "    content=news[i][\"summary\"]\n",
    "\n",
    "    preprocess_text = content.strip().replace(\"\\n\",\"\")\n",
    "    t5_prepared_Text = \"summarize: \"+preprocess_text\n",
    "\n",
    "    tokenized_text = tokenizer.encode(t5_prepared_Text, return_tensors=\"pt\").to(device)\n",
    "\n",
    "\n",
    "    # summmarize \n",
    "    summary_ids = model.generate(tokenized_text,\n",
    "                                        num_beams=4,\n",
    "                                        no_repeat_ngram_size=2,\n",
    "                                        min_length=50,\n",
    "                                        max_length=200,\n",
    "                                        early_stopping=True)\n",
    "\n",
    "    output = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "    sentences = sent_tokenizer.tokenize(output)\n",
    "    sentences = [sent.capitalize() for sent in sentences]\n",
    "    output=\"\"\n",
    "    for sent in sentences:\n",
    "        output+=sent+' '\n",
    "    news[i][\"summary\"]=output.strip()\n",
    "    print(\"Summarised:\", i+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94191c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "username=\"\"\n",
    "password=\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73166674",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_database():\n",
    "    # Provide the mongodb atlas url to connect python to mongodb using pymongo\n",
    "    CONNECTION_STRING = f\"\"\n",
    "    try:\n",
    "        conn = MongoClient(CONNECTION_STRING, ssl_cert_reqs=ssl.CERT_NONE)\n",
    "        print(\"Connected successfully!!!\")\n",
    "        return conn.firstlight\n",
    "    except:  \n",
    "        print(\"Could not connect to MongoDB\")\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33eda732",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = get_database()\n",
    "try:\n",
    "    db[\"news\"].insert_many(news)\n",
    "    print(\"Success\")\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
