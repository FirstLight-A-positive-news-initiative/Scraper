{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbae7de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "#BERT\n",
    "from transformers import pipeline\n",
    "# Allocate a pipeline for sentiment-analysis\n",
    "classifier = pipeline('sentiment-analysis')\n",
    "import ssl\n",
    "\n",
    "#Summary\n",
    "import torch\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration, T5Config\n",
    "model = T5ForConditionalGeneration.from_pretrained('t5-small')\n",
    "tokenizer = T5Tokenizer.from_pretrained('t5-small')\n",
    "device = torch.device('cpu')\n",
    "\n",
    "#Capitalize the Sentences\n",
    "import textwrap\n",
    "import nltk.data\n",
    "sent_tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "\n",
    "import pymongo\n",
    "from pymongo import MongoClient\n",
    "\n",
    "from bs4 import BeautifulSoup \n",
    "import re\n",
    "import urllib.request, urllib.parse, urllib.error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9de5075",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_url = 'https://edition.cnn.com'\n",
    "world_url = 'https://edition.cnn.com/world'\n",
    "politics_url = 'https://edition.cnn.com/politics'\n",
    "health_url = 'https://edition.cnn.com/health'\n",
    "entertainment_url = 'https://edition.cnn.com/entertainment'\n",
    "india_url ='https://edition.cnn.com/india'\n",
    "business_url = 'https://edition.cnn.com/business'\n",
    "sports_url = 'https://edition.cnn.com/sport'\n",
    "technology_url = 'https://edition.cnn.com/business/tech'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd27ed4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "datedata=pd.read_csv(\"./LastRunDate.csv\")\n",
    "pastdate=datetime.fromtimestamp(datedata.loc[datedata[\"Scraper and Model\"]==\"cnn\", \"Date\"])\n",
    "lastdate=pastdate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de5cfa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getParseUrl(link):\n",
    "    driver = getDriver()\n",
    "    driver.get(link)\n",
    "    webContent = driver.page_source\n",
    "    \n",
    "    data = BeautifulSoup(webContent, 'html.parser')\n",
    "    driver.close()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1539db35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getParseUrlStatic(link):\n",
    "    response = urllib.request.urlopen(link)\n",
    "    webContent = response.read()\n",
    "    \n",
    "    data = BeautifulSoup(webContent, 'html.parser')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cfeb758",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNewsLinks(data):\n",
    "    headlines = data.find_all(class_ = \"cd__headline\")\n",
    "    links = []\n",
    "    for headline in headlines:\n",
    "        link = headline.a[\"href\"]\n",
    "        if link[:5] != 'https':\n",
    "            link = cnn_url + link\n",
    "        links.append(link)\n",
    "    return links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f8c98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDriver():\n",
    "    driver = webdriver.Chrome(executable_path=r'./chromedriver_win32/chromedriver')\n",
    "    return driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a46a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getStringFromTags(tag):\n",
    "    data = tag.contents\n",
    "    string = \"\"\n",
    "    for content in data:\n",
    "        try:\n",
    "            string += content\n",
    "        except:\n",
    "            string += getStringFromTags(content)\n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70cbb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanDate(date):\n",
    "    date = date.split()\n",
    "    date = date[5] + \" \" + date[6] + \" \" + date[7] + \" \" + date[1]\n",
    "    utcdiff=datetime.now()-datetime.utcnow()\n",
    "    date =  datetime.strptime(date, \"%B %d, %Y %H%M\") + utcdiff\n",
    "    return date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092bf9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNewsFromLink(link, genre):\n",
    "    news = {}\n",
    "    try:\n",
    "        data = getParseUrlStatic(link)\n",
    "        news['title'] = data.h1.contents[0]\n",
    "        news['summary'] = \"\"\n",
    "        divs = data.find_all(True, {'class': [\"zn-body__paragraph\", \"Paragraph__component BasicArticle__paragraph BasicArticle__pad\", \"Paragraph__component\"]})\n",
    "        for div in divs:\n",
    "            news['summary'] += getStringFromTags(div)\n",
    "        try:\n",
    "            news['image_link'] = data.find('img')['data-src-full16x9']\n",
    "        except:\n",
    "            news['image_link'] = ''\n",
    "        if news['image_link'] == '':\n",
    "            try:\n",
    "                news['image_link'] = data.find('img')['data-src-large']\n",
    "            except:\n",
    "                news['image_link'] = ''\n",
    "        if news['image_link'] == '':\n",
    "            try:\n",
    "                news['image_link'] = data.find('img')['data-src-medium']\n",
    "            except:\n",
    "                news['image_link'] = ''\n",
    "        if news['image_link'] == '':\n",
    "            try:\n",
    "                news['image_link'] = data.find('img')['data-src-small']\n",
    "            except:\n",
    "                news['image_link'] = ''\n",
    "        if news['image_link'] == '':\n",
    "            try:\n",
    "                news['image_link'] = data.find('img')['data-src-mini']\n",
    "            except:\n",
    "                news['image_link'] = ''\n",
    "        if news['image_link'] == '':\n",
    "            try:\n",
    "                news['image_link'] = data.find('img')['src']\n",
    "            except:\n",
    "                news['image_link'] = ''\n",
    "        if news['image_link'] == '' or (news['image_link'][-4:]!='.jpg' and news['image_link'][-4:]!='.png' and news['image_link'][-4:]!='.gif' and news['image_link'][-5:]!='.jpeg'):\n",
    "            try:\n",
    "                news['image_link'] = data.find_all('img')[1]['src']\n",
    "            except:\n",
    "                news['image_link'] = ''\n",
    "        if news['image_link'] == '' or (news['image_link'][-4:]!='.jpg' and news['image_link'][-4:]!='.png' and news['image_link'][-4:]!='.gif' and news['image_link'][-5:]!='.jpeg'):\n",
    "            news['image_link']=''\n",
    "            \n",
    "        news['image_link'] = news['image_link'].replace('e_blur:500,', '')\n",
    "        news['image_link'] = news['image_link'].replace('q_auto:low,', '')\n",
    "        news['image_link'] = news['image_link'].replace('w_50,', '')\n",
    "        news['image_link'] = news['image_link'].replace('c_fill,', '')\n",
    "        news['image_link'] = news['image_link'].replace('g_auto,', '')\n",
    "        news['image_link'] = news['image_link'].replace('h_50,', '')\n",
    "        news['image_link'] = news['image_link'].replace('h_28,', '')\n",
    "        \n",
    "        news['link'] = link\n",
    "        global lastdate\n",
    "        try: \n",
    "            news['date'] = cleanDate(data.find_all('p', class_='update-time')[0].contents[0])\n",
    "        except:\n",
    "            news['date'] = pastdate\n",
    "        news['positivity_score'] = 0\n",
    "        news['genre'] = genre\n",
    "        if news['summary'] == '':\n",
    "            news = {}\n",
    "        try: \n",
    "            news['summary'] = news['summary'].split('(CNN)', 1)[1]\n",
    "        except:\n",
    "            news['summary'] = news['summary']\n",
    "\n",
    "        if news['date']<=pastdate:\n",
    "            news = {}\n",
    "            # print(\"Old News \" + link)\n",
    "        \n",
    "        if lastdate<news['date']:\n",
    "            lastdate=news['date']\n",
    "    except:\n",
    "        news = {}\n",
    "        # print(\"Cannot get this news \" + link)\n",
    "    return news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a4aea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDataFromUrl(url, genre):\n",
    "    data = getParseUrl(url)\n",
    "    links = getNewsLinks(data)\n",
    "    news = [getNewsFromLink(link, genre) for link in links if link[:23] == 'https://edition.cnn.com']\n",
    "    return news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a976288",
   "metadata": {},
   "outputs": [],
   "source": [
    "news = []\n",
    "for genre in ['world', 'politics', 'entertainment', 'india', 'business', 'technology', 'health']:\n",
    "    url = cnn_url + '/' + genre\n",
    "    if genre=='technology':\n",
    "        url=technology_url\n",
    "    print(genre)\n",
    "    cur_news = getDataFromUrl(url, genre)\n",
    "    for new in cur_news:\n",
    "        if len(new)>0:\n",
    "            news.append(new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbea2f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "datedata=pd.read_csv(\"./LastRunDate.csv\")\n",
    "datedata.loc[datedata[\"Scraper and Model\"]==\"cnn\", \"Date\"]=datetime.timestamp(lastdate)\n",
    "datedata.to_csv(\"LastRunDate.csv\", index=False)\n",
    "print(\"Latest News Found:\", lastdate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ebda446",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af74436",
   "metadata": {},
   "outputs": [],
   "source": [
    "news = pd.DataFrame(news).dropna()\n",
    "news.drop_duplicates(keep='first', inplace=True)\n",
    "news.drop_duplicates(['title', 'genre'], keep='first', inplace=True)\n",
    "news = news.to_dict('records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3073c01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ab65ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(news)):\n",
    "    x={'label': 'NEGATIVE', 'score': 1}\n",
    "    try:\n",
    "        x = classifier(news[i][\"summary\"])[0]\n",
    "    except:\n",
    "        pass\n",
    "    z={'label': 'NEGATIVE', 'score': 1}\n",
    "    try:\n",
    "        z = classifier(' '.join(news[i][\"summary\"].split()[:300]))[0]\n",
    "    except:\n",
    "        z = classifier(' '.join(news[i][\"summary\"].split()[:150]))[0]\n",
    "    news[i][\"positivity_score\"] = max(x['score']/2+0.5 if x['label']=='POSITIVE' else (0.5-x['score']/2), z['score']/2+0.5 if z['label']=='POSITIVE' else (0.5-z['score']/2))\n",
    "    news[i][\"positivity_score\"] = int(float(news[i][\"positivity_score\"])*100)\n",
    "    if news[i][\"genre\"]==\"science\" or news[i][\"genre\"]=='health':\n",
    "        news[i][\"positivity_score\"] += 50\n",
    "        news[i][\"positivity_score\"] = min(news[i][\"positivity_score\"], 100)\n",
    "    if news[i][\"genre\"]==\"technology\" or news[i][\"genre\"]==\"business\" or news[i][\"genre\"]==\"entertainment\":\n",
    "        news[i][\"positivity_score\"] += 25\n",
    "        news[i][\"positivity_score\"] = min(news[i][\"positivity_score\"], 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e6d4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7f170b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removes non-alphabetic characters:\n",
    "def text_strip(column):\n",
    "    for row in column:\n",
    "        \n",
    "        #ORDER OF REGEX IS VERY VERY IMPORTANT!!!!!!\n",
    "        \n",
    "        row=re.sub(\"(\\\\t)\", ' ', str(row)).lower() #remove escape charecters\n",
    "        row=re.sub(\"(\\\\r)\", ' ', str(row)).lower() \n",
    "        row=re.sub(\"(\\\\n)\", ' ', str(row)).lower()\n",
    "        \n",
    "        row=re.sub(\"(__+)\", ' ', str(row)).lower()   #remove _ if it occors more than one time consecutively\n",
    "        row=re.sub(\"(--+)\", ' ', str(row)).lower()   #remove - if it occors more than one time consecutively\n",
    "        row=re.sub(\"(~~+)\", ' ', str(row)).lower()   #remove ~ if it occors more than one time consecutively\n",
    "        row=re.sub(\"(\\+\\++)\", ' ', str(row)).lower()   #remove + if it occors more than one time consecutively\n",
    "        row=re.sub(\"(\\.\\.+)\", ' ', str(row)).lower()   #remove . if it occors more than one time consecutively\n",
    "        \n",
    "        row=re.sub(r\"[<>()|&©ø\\[\\]\\'\\\",;?~*!]\", ' ', str(row)).lower() #remove <>()|&©ø\"',;?~*!\n",
    "        \n",
    "        row=re.sub(\"(mailto:)\", ' ', str(row)).lower() #remove mailto:\n",
    "        row=re.sub(r\"(\\\\x9\\d)\", ' ', str(row)).lower() #remove \\x9* in text\n",
    "        row=re.sub(\"([iI][nN][cC]\\d+)\", 'INC_NUM', str(row)).lower() #replace INC nums to INC_NUM\n",
    "        row=re.sub(\"([cC][mM]\\d+)|([cC][hH][gG]\\d+)\", 'CM_NUM', str(row)).lower() #replace CM# and CHG# to CM_NUM\n",
    "        \n",
    "        \n",
    "        row=re.sub(\"(\\.\\s+)\", ' ', str(row)).lower() #remove full stop at end of words(not between)\n",
    "        row=re.sub(\"(\\-\\s+)\", ' ', str(row)).lower() #remove - at end of words(not between)\n",
    "        row=re.sub(\"(\\:\\s+)\", ' ', str(row)).lower() #remove : at end of words(not between)\n",
    "        \n",
    "        row=re.sub(\"(\\s+.\\s+)\", ' ', str(row)).lower() #remove any single charecters hanging between 2 spaces\n",
    "        \n",
    "        #Replace any url as such https://abc.xyz.net/browse/sdf-5327 ====> abc.xyz.net\n",
    "        try:\n",
    "            url = re.search(r'((https*:\\/*)([^\\/\\s]+))(.[^\\s]+)', str(row))\n",
    "            repl_url = url.group(3)\n",
    "            row = re.sub(r'((https*:\\/*)([^\\/\\s]+))(.[^\\s]+)',repl_url, str(row))\n",
    "        except:\n",
    "            pass #there might be emails with no url in them\n",
    "        \n",
    "\n",
    "        \n",
    "        row = re.sub(\"(\\s+)\",' ',str(row)).lower() #remove multiple spaces\n",
    "        \n",
    "        #Should always be last\n",
    "        row=re.sub(\"(\\s+.\\s+)\", ' ', str(row)).lower() #remove any single charecters hanging between 2 spaces\n",
    "\n",
    "        row.strip().replace(\"\\n\",\"\")\n",
    "        \n",
    "        yield row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f3aea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(news)):\n",
    "    content=news[i][\"summary\"]\n",
    "\n",
    "    preprocess_text = content.strip().replace(\"\\n\",\"\")\n",
    "    t5_prepared_Text = \"summarize: \"+preprocess_text\n",
    "\n",
    "    tokenized_text = tokenizer.encode(t5_prepared_Text, return_tensors=\"pt\").to(device)\n",
    "\n",
    "\n",
    "    # summmarize \n",
    "    summary_ids = model.generate(tokenized_text,\n",
    "                                        num_beams=4,\n",
    "                                        no_repeat_ngram_size=2,\n",
    "                                        min_length=50,\n",
    "                                        max_length=200,\n",
    "                                        early_stopping=True)\n",
    "\n",
    "    output = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "    sentences = sent_tokenizer.tokenize(output)\n",
    "    sentences = [sent.capitalize() for sent in sentences]\n",
    "    output=\"\"\n",
    "    for sent in sentences:\n",
    "        output+=sent+' '\n",
    "    news[i][\"summary\"]=output.strip()\n",
    "    print(\"Summarised:\", i+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ebe671",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5e01b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "username=\"\"\n",
    "password=\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217c6282",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_database():\n",
    "    # Provide the mongodb atlas url to connect python to mongodb using pymongo\n",
    "    CONNECTION_STRING = f\"\"\n",
    "    try:\n",
    "        conn = MongoClient(CONNECTION_STRING, ssl_cert_reqs=ssl.CERT_NONE)\n",
    "        print(\"Connected successfully!!!\")\n",
    "        return conn.firstlight\n",
    "    except:  \n",
    "        print(\"Could not connect to MongoDB\")\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4172c695",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = get_database()\n",
    "try:\n",
    "    db[\"news\"].insert_many(news)\n",
    "    print(\"Success\")\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
